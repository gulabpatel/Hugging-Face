{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01: Behind the pipeline (PyTorch)",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gulabpatel/Hugging-Face/blob/main/Course/Chapter%202/01%3A%20Behind_the_pipeline_(PyTorch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GnlLO0ojJXT"
      },
      "source": [
        "Chapter 2 : https://huggingface.co/course/chapter2?fw=pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bd6bEy6NNVq"
      },
      "source": [
        "# Behind the pipeline (PyTorch)\n",
        "\n",
        "\n",
        "There are many different architectures available in ðŸ¤— Transformers, with each one designed around tackling a specific task. Here is a non-exhaustive list:\n",
        "\n",
        "* *Model (retrieve the hidden states)\n",
        "* *ForCausalLM\n",
        "* *ForMaskedLM\n",
        "* *ForMultipleChoice\n",
        "* *ForQuestionAnswering\n",
        "* *ForSequenceClassification\n",
        "* *ForTokenClassification\n",
        "and others ðŸ¤—\n",
        "\n",
        "\n",
        "For our example, we will need a model with a sequence classification head (to be able to classify the sentences as positive or negative). So, we wonâ€™t actually use the AutoModel class, but AutoModelForSequenceClassification:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Zd-xbBNNVu"
      },
      "source": [
        "Install the Transformers and Datasets libraries to run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q3376d0NNVu"
      },
      "source": [
        "! pip install datasets transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBG8NjBNNVv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f047d82-3f9a-4e92-abc4-de078488771f"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "classifier([\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
        "    \"I hate this so much!\",\n",
        "])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9598047137260437},\n",
              " {'label': 'NEGATIVE', 'score': 0.9994558095932007}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrY6eMztNNVy"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zo94C78NNVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7106ae41-9376-46bd-cafe-055780fb591a"
      },
      "source": [
        "raw_inputs = [\n",
        "    \"I've been waiting for a HuggingFace course my whole life.\", \n",
        "    \"I hate this so much!\",\n",
        "]\n",
        "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(inputs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
            "          2607,  2026,  2878,  2166,  1012,   102],\n",
            "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNatamq2NNVz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d969951-ce0a-4ebc-f982-4910842fb7bf"
      },
      "source": [
        "from transformers import AutoModel\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModel.from_pretrained(checkpoint)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8b0DL76NNV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de41cf86-bef4-4769-87f2-5288b8cec39d"
      },
      "source": [
        "outputs = model(**inputs)\n",
        "print(outputs.last_hidden_state.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 16, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ6oCHCPNNV1"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL_Qv9eGNNV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98ee4b8-b371-465d-d3b2-1abc3b1179f0"
      },
      "source": [
        "print(outputs.logits.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX4Z5XslNNV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c9bbe70-6566-4519-90d6-4711e0d2f3e9"
      },
      "source": [
        "print(outputs.logits)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.5607,  1.6123],\n",
            "        [ 4.1692, -3.3464]], grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys0sjvhkNNV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e23fa8-fdd4-47af-e68b-9fe5002824cc"
      },
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.0195e-02, 9.5980e-01],\n",
            "        [9.9946e-01, 5.4418e-04]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3heAAaY8NNV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d752c1a6-435c-476c-d795-7f386a8098f8"
      },
      "source": [
        "model.config.id2label"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}
